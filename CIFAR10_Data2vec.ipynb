{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_Data2vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPAHeYzdYM+ex65jrN3NMy+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AokiMasataka/colab/blob/main/CIFAR10_Data2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data2vec\n",
        "参考: https://ai.facebook.com/blog/the-first-high-performance-self-supervised-algorithm-that-works-for-speech-vision-and-text"
      ],
      "metadata": {
        "id": "RqLWhRZ1pIAf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yiu4eqY-Y31W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional\n",
        "from torch.backends import cudnn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.models import resnet18\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# set seed\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "cudnn.deterministic = True\n",
        "cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, cut_out_size=None):\n",
        "        self.data_list = data\n",
        "        self.cut_out_size = cut_out_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        one_data = self.data_list[index]\n",
        "        image = one_data[0]\n",
        "        image = np.array(image, dtype=np.float32) / 255.0\n",
        "        image = image.transpose(2, 0, 1)\n",
        "        image = torch.tensor(image, dtype=torch.float32)\n",
        "        if self.cut_out_size is not None:\n",
        "            cut_out_image = self.cut_out(deepcopy(image))\n",
        "            return image, cut_out_image\n",
        "        return image, one_data[1]\n",
        "    \n",
        "    def cut_out(self, image):\n",
        "        x_pos = np.random.randint(0, 32 - self.cut_out_size)\n",
        "        y_pos = np.random.randint(0, 32 - self.cut_out_size)\n",
        "        image[:, x_pos: x_pos + self.cut_out_size, y_pos: y_pos + self.cut_out_size] = 0\n",
        "        return image"
      ],
      "metadata": {
        "id": "zYptbnzJY_du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CIFAR10(root='.', train=True, transform=None, download=True)\n",
        "valid_data = CIFAR10(root='.', train=False, transform=None, download=True)\n",
        "\n",
        "cut_out_data = [train_data[i] for i in range(0, 20000)]\n",
        "train_data = [train_data[i] for i in range(20000, 40000)]\n",
        "\n",
        "cut_out_dataset = MyDataset(cut_out_data, cut_out_size=16)\n",
        "train_dataset = MyDataset(train_data)\n",
        "valid_dataset = MyDataset(valid_data)\n",
        "\n",
        "cut_out_loader = DataLoader(cut_out_dataset, batch_size=64, shuffle=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kko_NJa2ZBKC",
        "outputId": "de4ba838-79f3-468a-c017-4b4dd3aaeabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "origin_images, cut_out_images = iter(cut_out_loader).__next__()\n",
        "origin_image = origin_images[0]\n",
        "cut_out_image = cut_out_images[0]\n",
        "print(origin_image.shape, origin_image.min(), origin_image.max())\n",
        " \n",
        "origin_image = np.array(origin_image).transpose((1,2,0))\n",
        "cut_out_image = np.array(cut_out_image).transpose((1,2,0))\n",
        "image = np.concatenate((origin_image, cut_out_image), axis=1)\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "QVn4sh7waHiM",
        "outputId": "ce80704a-ab4e-4be3-b77a-0f28fe6d9647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32]) tensor(0.) tensor(1.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd0dd1d65d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomNet, self).__init__()\n",
        "        self.net = resnet18(pretrained=False, num_classes=10)\n",
        "    \n",
        "    def forward(self, image):\n",
        "        return self.net(image)\n",
        "    \n",
        "    def extract_features(self, image):\n",
        "        features = []\n",
        "        x = self.net.conv1(image)\n",
        "        x = self.net.bn1(x)\n",
        "        x = self.net.relu(x)\n",
        "        # x = self.net.maxpool(x)\n",
        "\n",
        "        x_1 = self.net.layer1(x)\n",
        "        x_2 = self.net.layer2(x_1)\n",
        "        features.append(x_2)\n",
        "        x_3 = self.net.layer3(x_2)\n",
        "        features.append(x_3)\n",
        "        x_4 = self.net.layer4(x_3)\n",
        "        features.append(x_4)\n",
        "        return features"
      ],
      "metadata": {
        "id": "RiT1oJqVcglj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def valid(model, valid_loader):\n",
        "    model.eval()\n",
        "    n_labels = valid_loader.dataset.__len__()\n",
        "    acc = 0\n",
        "    mean_loss = 0\n",
        "    for images, labels in valid_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        pred = model(images)\n",
        "        loss = functional.cross_entropy(pred, labels)\n",
        "        acc += sum(pred.cpu().argmax(dim=1) == labels.cpu())\n",
        "        mean_loss += loss.item()\n",
        "    acc = acc / n_labels\n",
        "    mean_loss = mean_loss / n_labels\n",
        "    return acc, mean_loss"
      ],
      "metadata": {
        "id": "e5L2MnSie0Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    max_acc = float('-Inf')\n",
        "    for epoch in range(1, 8 + 1):\n",
        "        model.train()\n",
        "        loss_list = []\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            pred = model(images)\n",
        "            loss = functional.cross_entropy(pred, labels)\n",
        "            loss_list.append(loss.item())\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        mean_loss = np.mean(loss_list)\n",
        "        acc, valid_loss = valid(model, valid_loader)\n",
        "        if max_acc < acc:\n",
        "            max_acc = acc\n",
        "        print(f'INFO: [Train]  epoch: {epoch}  train loss: {mean_loss:.6f}  valid loss: {valid_loss:.6f}  acc: {acc:.3f}')\n",
        "    return max_acc"
      ],
      "metadata": {
        "id": "mmFTKpbpfGbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_data2vec(student_model, teacher_model):\n",
        "    teacher_model.eval()\n",
        "    optimizer = optim.Adam(student_model.parameters(), lr=0.001)\n",
        "    for epoch in range(1, 8 + 1):\n",
        "        teacher_model.train()\n",
        "        loss_list = []\n",
        "        for origin_images, cut_out_image in cut_out_loader:\n",
        "            origin_images, cut_out_image = origin_images.to(device), cut_out_image.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                teacher_pred = teacher_model.extract_features(origin_images)\n",
        "            student_pred = student_model.extract_features(cut_out_image)\n",
        "\n",
        "            for i in range(3):\n",
        "                if i == 0:\n",
        "                    loss = functional.mse_loss(student_pred[i], teacher_pred[i])\n",
        "                else:\n",
        "                    loss = loss + functional.mse_loss(student_pred[i], teacher_pred[i])\n",
        "            \n",
        "            loss_list.append(loss.item())\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        mean_loss = np.mean(loss_list)\n",
        "        print(f'INFO: [Data2vec]  epoch: {epoch}  train loss: {mean_loss:.5f}')"
      ],
      "metadata": {
        "id": "aLgJNiOffCWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = CustomNet().to(device)\n",
        "teacher_model = CustomNet().to(device)\n",
        "\n",
        "teacher_acc = train(teacher_model)\n",
        "train_data2vec(student_model, teacher_model)\n",
        "student_acc = train(student_model)\n",
        "print(f'teacher model accuracy: {teacher_acc:.6f}')\n",
        "print(f'student model accuracy: {student_acc:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNdQJhl-kPfN",
        "outputId": "7fcbeab0-9b4c-4da9-c09e-b0827dd31e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: [Train]  epoch: 1  train loss: 1.590738  valid loss: 0.022196  acc: 0.489\n",
            "INFO: [Train]  epoch: 2  train loss: 1.228983  valid loss: 0.022207  acc: 0.498\n",
            "INFO: [Train]  epoch: 3  train loss: 1.024028  valid loss: 0.022832  acc: 0.503\n",
            "INFO: [Train]  epoch: 4  train loss: 0.879422  valid loss: 0.024810  acc: 0.489\n",
            "INFO: [Train]  epoch: 5  train loss: 0.745217  valid loss: 0.025140  acc: 0.507\n",
            "INFO: [Train]  epoch: 6  train loss: 0.642758  valid loss: 0.024148  acc: 0.549\n",
            "INFO: [Train]  epoch: 7  train loss: 0.539871  valid loss: 0.025799  acc: 0.541\n",
            "INFO: [Train]  epoch: 8  train loss: 0.440810  valid loss: 0.025516  acc: 0.559\n",
            "INFO: [Data2vec]  epoch: 1  train loss: 2.34821\n",
            "INFO: [Data2vec]  epoch: 2  train loss: 1.84837\n",
            "INFO: [Data2vec]  epoch: 3  train loss: 1.63932\n",
            "INFO: [Data2vec]  epoch: 4  train loss: 1.50388\n",
            "INFO: [Data2vec]  epoch: 5  train loss: 1.39695\n",
            "INFO: [Data2vec]  epoch: 6  train loss: 1.31331\n",
            "INFO: [Data2vec]  epoch: 7  train loss: 1.25756\n",
            "INFO: [Data2vec]  epoch: 8  train loss: 1.21805\n",
            "INFO: [Train]  epoch: 1  train loss: 1.093008  valid loss: 0.016842  acc: 0.620\n",
            "INFO: [Train]  epoch: 2  train loss: 0.841930  valid loss: 0.017041  acc: 0.626\n",
            "INFO: [Train]  epoch: 3  train loss: 0.683097  valid loss: 0.017858  acc: 0.633\n",
            "INFO: [Train]  epoch: 4  train loss: 0.552494  valid loss: 0.020070  acc: 0.613\n",
            "INFO: [Train]  epoch: 5  train loss: 0.464514  valid loss: 0.028606  acc: 0.532\n",
            "INFO: [Train]  epoch: 6  train loss: 0.382359  valid loss: 0.027486  acc: 0.573\n",
            "INFO: [Train]  epoch: 7  train loss: 0.310277  valid loss: 0.024260  acc: 0.617\n",
            "INFO: [Train]  epoch: 8  train loss: 0.223374  valid loss: 0.027561  acc: 0.621\n",
            "teacher model accuracy: inf\n",
            "student model accuracy: inf\n"
          ]
        }
      ]
    }
  ]
}